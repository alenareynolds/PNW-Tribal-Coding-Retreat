[
  {
    "objectID": "mapping.html",
    "href": "mapping.html",
    "title": "2  Mapping",
    "section": "",
    "text": "2.1 Goals and Outcomes\nThroughout this section we’ll use the following packages:\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(sf)\nlibrary(ggspatial)\nlibrary(leaflet)\nlibrary(Rspatialworkshop)\nlibrary(mapview)\nmapviewOptions(fgb=FALSE)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(terra)\nR is fantastic for making publication quality static maps, and for generating repetitive graphics through scripts; we’ve already seen examples of how to make simple maps using base plotting,ggplot, and tmap. There are also several packages in R that link R code to plotting libraries developed in Javascript (or other languages) for interactive plotting and web integration.\nIt can be hard to decide which mapping packages to learn and use - some nice advice from Martin Tennekes who created tmap:\nAlso, as pointed out in Spatial Data Science by Edzar Pebesma and Roger Bivand, ‘Every plot is a projection’ so it’s essential to have an understanding of coordinate reference systems and projections when visualizing spatial data in R - as they point out ‘any time we visualize, in any way, the world on a flat device, we project: we convert ellipsoidal coordinates into Cartesian coordinate’.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "mapping.html#goals-and-outcomes",
    "href": "mapping.html#goals-and-outcomes",
    "title": "2  Mapping",
    "section": "",
    "text": "Gain familiarity with plotting and visualizing spatial data in R\nWork with four specific visualization and plotting libraries:\n\nggplot2\nleaflet\nmapview\ntmap\n\n\n\n\n\n\n\n\nIf you know some ggplot, don’t care about interactive maps, and don’t want to spend a lot of time learning new packages, use ggplot\n\nIf you want interactive maps as flexible as possible, use leaflet\n\nIf you want to simply explore spatial objects ineractively as easily as possible, use mapview\n\nOtherwise, use tmap!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "mapping.html#ggplot2",
    "href": "mapping.html#ggplot2",
    "title": "2  Mapping",
    "section": "\n2.2 ggplot2",
    "text": "2.2 ggplot2\nggplot2 now has support for geom_sf that was developed in conjunction with the development of sf and helps creating publication quality maps directly using sf objects. An introduction to this is found in Moreno and Basille (2018).\nHere we’ll show some of the useful functionality of ggplot2 with geom_sf objects pulling census and American Community Survey data using the tidycensus package.\n\n\n\n\n\n\nNote\n\n\n\nNote that to use tidycensus you’ll need to set your Census API key. A key can be obtained from here.\n\n\n\nmult_tracts &lt;- tidycensus::get_acs(state='OR',county='Multnomah',geography='tract', variables=c('B19013_001','B16010_028','B01003_001'), geometry=TRUE)  \n\nGetting data from the 2019-2023 5-year ACS\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |======================================================================| 100%\n\n# tidy data\nmult_wide &lt;- mult_tracts |&gt; \n  sf::st_transform(2955) |&gt; #UTM 11N\n  dplyr::filter(!is.na(estimate)) |&gt; \n  tidyr::pivot_wider(\n    names_from = c(\"variable\"),\n    values_from = c(\"estimate\",\"moe\")\n  ) |&gt; \n  dplyr::relocate(geometry, .after = last_col())\n\nnames(mult_wide)[3:5] &lt;- c('Total_Pop','College_Education','Median_Income')\nmult_wide &lt;- mult_wide |&gt; \n  dplyr::mutate(Perc_College_Ed = (College_Education / Total_Pop) * 100) |&gt; \n  dplyr::filter(!is.na(Median_Income) & !is.na(Perc_College_Ed))\n  \n    \n# Median Income\nmult_wide |&gt; \n  ggplot() + geom_sf(aes(fill = Median_Income)) + \n  scale_y_continuous() +\n  scale_fill_viridis_c(option = \"mako\") +\n  theme_minimal_grid(12)\n\n\n\n\n\n\n\n\nmult_wide |&gt; \n  ggplot() + geom_sf(aes(fill = Perc_College_Ed)) + \n  scale_y_continuous() +\n  scale_fill_viridis_c(option = \"mako\") +\n  theme_minimal_grid(12)\n\n\n\n\n\n\n\nA great resource for mapping with ggplot2 is this blog post from 2018.\n\n\n\n\n\n\nExercise\n\n\n\nUsing the blog post link above, get counties for your state using tigris (or other!) package. Ignore the extra packages and some of the bells and whistles in the blog post, but try using a few of their ideas and adding a few of the ggplot parameters to make an interesting map using county data. You can try loading city data as well.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOne idea\n\ncounties &lt;- tigris::counties(\"Oregon\", cb = TRUE)\ncounties &lt;- counties |&gt; \n  sf::st_transform(2991) |&gt; \n  dplyr::mutate(area=as.numeric(st_area(counties)))\n\nggplot() +\n    geom_sf(data = counties, fill = NA, color = gray(.5)) \n\n\n\n\n\n\n\n\nggplot() +\n    geom_sf(data = counties, aes(fill = area))  +\n  scale_fill_viridis_c(trans = \"sqrt\", alpha = .4) +\n    \n    theme(panel.grid.major = element_line(color = gray(0.5), linetype = \"dashed\", \n        size = 0.5), panel.background = element_rect(fill = \"aliceblue\")) +\n    annotation_scale(location = \"bl\", width_hint = 0.4) +\n    annotation_north_arrow(location = \"tr\", which_north = \"true\",\n        style = north_arrow_fancy_orienteering)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "mapping.html#leaflet",
    "href": "mapping.html#leaflet",
    "title": "2  Mapping",
    "section": "\n2.3 leaflet",
    "text": "2.3 leaflet\nLeaflet is an extremely popular open-source javascript library for interactive web mapping, and the leaflet R package allows R users to create Leaflet maps from R. Leaflet can plot sf or sp objects, or x / y coordinates, and can plot points, lines or polygons. There are a number of base layers you can choose from. It’s worth spending some time exploring the excellent Leaflet for R site.\nHere we make a simple leaflet map of our the location of the EPA Pacific Ecological Systems Division lab in Corvallis where I work with a custom popup we create:\n\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.epa.gov/greeningepa/pacific-ecological-systems-division-pesd-laboratory'&gt;EPA Lab Corvallis&lt;/a&gt;&lt;/b&gt;\",\n  \"200 S.W. 35th Street \",\n  \"Corvallis, OR 97333 \"\n)\n\nleaflet()  |&gt;  addTiles()  |&gt; \n  addPopups(-123.290391, 44.565548,  content,\n    options = popupOptions(closeButton = FALSE)\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "mapping.html#mapview",
    "href": "mapping.html#mapview",
    "title": "2  Mapping",
    "section": "\n2.4 mapview",
    "text": "2.4 mapview\nMapview is a package designed for quick and easy interactive visualizations of spatial data - it makes use of leaflet but simplifies mapping functions compared to the leaflet package.\nIt’s easy to layer features with mapview - you can supply a list of objects to mapview or use + syntax as with ggplot.\nHere we’ll plot stream gages within Benton County:\n\ncounties &lt;- counties(\"Oregon\", cb = TRUE)\nbenton &lt;- counties[counties$NAME=='Benton',]\nfpath &lt;- system.file(\"extdata\", \"Gages_flowdata.csv\", package=\"Rspatialworkshop\")\n\ngages &lt;- read_csv(fpath,show_col_types = FALSE)\ngages_sf &lt;- gages %&gt;%\n  st_as_sf(coords = c(\"LON_SITE\", \"LAT_SITE\"), crs = 4269, remove = FALSE) \nst_crs(gages_sf)==st_crs(benton)\n# remember spatial indexing from Geoprocessing section?\ngages_benton &lt;- gages_sf[benton,]\nmapview(gages_benton) + benton\n\nWe can also use handy convenience packages like the AOI package by Mike Johnson for flexible, term based geocoding to return areas of interest as sf objects and map them:\n\nAOI::aoi_ext(geo = \"Corvallis, OR\", wh = 10000, bbox = TRUE) |&gt; \n  sf::st_as_sf() |&gt;\n  AOI::aoi_map(returnMap = T)\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nGlance through the mapview basics and adjust legend and attributes. Take a look at mapview advanced controls as well and try plotting stations and the county polygon together, this time modifying features such as thicker black outline and transparent fill for the county outline and colorizing gages by their average flow (‘AVE’).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmapview(gages_benton,zcol='AVE') + mapview(benton, alpha.regions=.07, color='black', lwd=2)\n\n\n\n\n\n\n\n\n\n2.4.1 Adding Web Map services in mapview\n\nWe’ll visualize data with mapview and load a web map service layers alongside using mapview and underlying leaflet functionality.\nFirst we load load an excel file containing coordinate information in a known projection and promote to an sf spatial data frame.\n\nfpath &lt;- system.file(\"extdata\", \"Station_Locations.xlsx\", package=\"Rspatialworkshop\")\nstations &lt;- read_xlsx(fpath)\nglimpse(stations)\n\nRows: 31\nColumns: 3\n$ Station &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\",…\n$ x       &lt;dbl&gt; -2140749, -2140111, -2124688, -2125545, -1664112, 1606578, -17…\n$ y       &lt;dbl&gt; 2502887, 2469697, 2533842, 2556987, 2770644, 2698398, 2664873,…\n\nsummary(stations$x)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-2259078 -2124688 -1561956 -1630593 -1454137  1606578        2 \n\n# common clean up steps for spatial data - we can't use data missing coordinates so drop those records\nstations &lt;- stations[complete.cases(stations),]\n# often spatial data in projected coordinates will have missing negative values for x values - common thing to fix:\nstations$x[stations$x &gt; 0] &lt;- 0 - stations$x[stations$x &gt; 0]\nstations &lt;- stations  |&gt;  \n  st_as_sf(coords = c(\"x\", \"y\"), remove = FALSE)\n\n# in this case we know the particular Albers projection and have the information as a proj string\nst_crs(stations) &lt;- \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\" \n\nBasic interactive map of our spatial stations with mapview:\n\nmapview(stations)\n\n\n\n\n\nHere we’ll load a web map servcice (WMS) for the National Hydrography dataset. We’re looking at stream stations so imagine we want to visualize how closely these sites match a known rivers and stream network:\n\n# create a mapview object with our stations:\nm &lt;- mapview(stations, legend=FALSE)\n\n# we configure the map attribute of our mapview object - try:\n# 'attributes(m) \n# to see those attributes\n\n#  The map attribute for mapview accepts leaflet methods - in this case we use addWMSTiles to add web map service tiles to the map\nm@map &lt;- m@map  |&gt;  addWMSTiles(group = 'NHDPlus',\n                              \"https://watersgeo.epa.gov/arcgis/services/NHDPlus_NP21/NHDSnapshot_NP21/MapServer/WmsServer?\",\n                              layers  = 4,\n                              options = WMSTileOptions(format = \"image/png\", transparent = TRUE),\n                              attribution = \"\")  |&gt;  addWMSTiles(group = 'NHDPlusHR',\n                                                                \"https://hydro.nationalmap.gov/arcgis/services/NHDPlus_HR/MapServer/WMSServer?\",\n                                                                layers  = 9,\n                                                                options = WMSTileOptions(format = \"image/png\", transparent = TRUE),\n                                                                attribution = \"\")   |&gt;  mapview:::mapViewLayersControl(names = c(\"NHDPlus\",\"NHDPlusHR\"))\nm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "mapping.html#tmap",
    "href": "mapping.html#tmap",
    "title": "2  Mapping",
    "section": "\n2.5 tmap",
    "text": "2.5 tmap\ntamp uses the same syntax as ggplot: the grammar of graphics - and it supports both static and interactive modes. Like ggplot2, each dataset added to a tmap plot can be mapped in a number of different ways such as location, color, size, etc. The Making maps with R section of Geocomputation with R has an excellent and in depth treatment of using tmap.\nWe can explore the basics using the counties of Oregon data we’ve been using in previous examples and exersices.\n\n# Add fill layer to Oregon counties\ntm_shape(counties) +\n  tm_fill() \n\n\n\n\n\n\n# Add border layer to Oregon counties\ntm_shape(counties) +\n  tm_borders() \n\n\n\n\n\n\n# Add fill and border layers to Oregon counties\ntm_shape(counties) +\n  tm_fill() +\n  tm_borders() \n\n\n\n\n\n\n\n\n2.5.1 Choropleths with tmap\n\n\ntm_shape(mult_wide) + tm_polygons(\"Median_Income\")\n\n\n\n\n\n\n\n\ntm_shape(mult_wide) + tm_polygons(\"Perc_College_Ed\")\n\n\n\n\n\n\n\nThat’s a pretty basic map - we can adjust a number of settings such as:\n\nbreaks: we can set different breaks for our map\nbins: we can control the number of bins\npalette: we can change the color palette\nlayout: put the legend outside of the map, increase legend width\n\nThese are just a few - let’s play with those to start with.\n\nbreaks = c(0, 20, 40, 80)\nt1 &lt;- tm_shape(mult_wide) + tm_polygons(\"Perc_College_Ed\", breaks=breaks,palette = \"BuGn\") + tm_layout(legend.outside=TRUE, legend.outside.position = \"right\", legend.outside.size=.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_tm_polygons()`: migrate the argument(s) related to the scale of\nthe visual variable `fill` namely 'breaks', 'palette' (rename to 'values') to\nfill.scale = tm_scale(&lt;HERE&gt;).\n\nt2 &lt;- tm_shape(mult_wide) + tm_polygons(\"Median_Income\", n=3,palette = \"BuGn\") + tm_layout(legend.outside=TRUE, legend.outside.position = \"right\", legend.outside.size=.5)\ntmap_arrange(t1, t2, nrow = 2)\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"BuGn\" is named\n\"brewer.bu_gn\"\nMultiple palettes called \"bu_gn\" found: \"brewer.bu_gn\", \"matplotlib.bu_gn\". The first one, \"brewer.bu_gn\", is returned.\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"BuGn\" is named\n\"brewer.bu_gn\"\nMultiple palettes called \"bu_gn\" found: \"brewer.bu_gn\", \"matplotlib.bu_gn\". The first one, \"brewer.bu_gn\", is returned.\n\n\n\n\n\n\n\n\n\n2.5.2 Faceting\n\n# Set mode to interactive\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n# Plot it out\ntm_shape(mult_wide) + tm_polygons(c(\"Median_Income\", \"Perc_College_Ed\")) + tm_facets(sync = TRUE, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.3 Plotting rasters and vectors with tmap\nBring in boundary and elevation of Crater Lake NP (datasets in Rspatialworkshop package) and plot with tmap\n\n# Set mode to plot\ntmap_mode(\"plot\")\ndata(CraterLake)\nraster_filepath &lt;- system.file(\"extdata\", \"elevation.tif\", package = \"Rspatialworkshop\")\nelevation &lt;- rast(raster_filepath)\n\nmap_crlk &lt;- tm_shape(CraterLake) + tm_polygons(lwd = 2)\nmap_crlkel = map_crlk +\n  tm_shape(elevation) + tm_raster(alpha = 0.7,palette = terrain.colors(12)) + tm_layout(legend.position = c(\"left\",\"bottom\"),\n          legend.width = 1)\n\nmap_crlkel\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTake a few minutes to read through Making maps with R in Geocomputation with R or the tmap GitHub pages and try to find a few modifications to plotting the elevation and the Crater Lake park boundary you can come up with to make a more interesting map with tmap.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntm_shape(elevation) +\n  tm_raster(title = \"Elevation\", \n            style = \"cont\",\n            palette = \"-Spectral\") +\n  tm_shape(CraterLake) +\n  tm_borders(col = \"black\", \n             lwd = 1)+ \n  tm_scale_bar(breaks = c(0, 10, 20),\n               text.size = .5,\n               position = c(\"left\", \"bottom\")) +\n  tm_grid(n.x = 4, n.y = 3) +\n  tm_compass(position = c(\"right\", \"top\"), \n             type = \"arrow\", \n             size = 1.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: instead of `style = \"cont\"`, use col.scale =\n`tm_scale_continuous()`.\nℹ Migrate the argument(s) 'palette' (rename to 'values') to\n  'tm_scale_continuous(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n! `tm_scale_bar()` is deprecated. Please use `tm_scalebar()` instead.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-Spectral\" is\nnamed \"spectral\" (in long format \"brewer.spectral\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mapping</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html",
    "href": "geoprocessing.html",
    "title": "3  Geoprocessing",
    "section": "",
    "text": "3.1 Goals and Outcomes\nThroughout this section we’ll use the following packages:\nlibrary(sf)\nlibrary(readr)\nlibrary(tigris)\nlibrary(AOI)\nlibrary(mapview)\nmapviewOptions(fgb=FALSE)\nlibrary(dplyr)\nlibrary(tmap)\nlibrary(Rspatialworkshop)\nlibrary(terra)\nlibrary(raster)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#goals-and-outcomes",
    "href": "geoprocessing.html#goals-and-outcomes",
    "title": "3  Geoprocessing",
    "section": "",
    "text": "Learn about fundamental spatial operations in R using spatial predicates in sf for:\n\nsubsetting\nspatial join\nbuffer\nlogical set operations - union / intersection\nclipping\ngenerating centroids and ‘casting’ to other geometry types\nraster operations\n\nmap algebra\ncropping and masking\nzonal operations\n\n\n\n\nExplore performing ‘map algebra’ type operations with raster data in R\nLearn how to do extract and zonal operations in R",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#operations-on-geometries",
    "href": "geoprocessing.html#operations-on-geometries",
    "title": "3  Geoprocessing",
    "section": "\n3.2 Operations on Geometries",
    "text": "3.2 Operations on Geometries\nThis breakdown of simple features follows for the most part this section in Spatial Data Science\nSimple and valid geometries\n\nCertain conditions have to be met with simple features:\n\nFor linestrings to be considered simple they must not self-intersect:\n\n\n\n\n(ls &lt;- st_linestring(rbind(c(0,0), c(1,1), c(2,2), c(0,2), c(1,1), c(2,0))))\n\nLINESTRING (0 0, 1 1, 2 2, 0 2, 1 1, 2 0)\n\n\n\n\n\n\n\n\n\n\n\n\nis_simple \n    FALSE \n\n\n\n\nFor polygons several other conditions have to be met to be simple:\n\npolygon rings are closed (the lastpoint equals the first)\npolygon holes (inner rings) are inside their exterior ring\npolygon inner rings maximally touch the exterior ring in single points, not over a line\na polygon ring does not repeat its own path\nin a multi-polygon, an external ring maximally touches another exterior ring in single points, not over a line\n\n\n\nWe can break down operations on geometries for vector features in the following way:\n\n\npredicates: a logical asserting a certain property is TRUE\n\n\nmeasures: a quantity (a numeric value, possibly with measurement unit)\n\ntransformations: newly generated geometries\n\nWe can look at these operations by what they operate on, whether the are single geometries, pairs, or sets of geometries:\n\n\nunary when it’s a single geometry\n\nbinary when it’s pairs of geometries\n\nn-ary when it’s sets of geometries\n\nUnary predicates work to describe a property of a geometry.\nA list of unary predicates:\n\n\npredicate\nmeaning\n\n\n\nis\nTests if geometry belongs to a particular class\n\n\nis_simple\nTests whether geometry is simple\n\n\nis_valid\nTest whether geometry is valid\n\n\nis_empty\nTests if geometry is empty\n\n\n\nA list of binary predicates is:\n\n\n\n\n\n\n\npredicate\nmeaning\ninverse of\n\n\n\ncontains\nNone of the points of A are outside B\nwithin\n\n\ncontains_properly\nA contains B and B has no points in common with the boundary of A\n\n\n\ncovers\nNo points of B lie in the exterior of A\ncovered_by\n\n\ncovered_by\nInverse of covers\n\n\n\n\ncrosses\nA and B have some but not all interior points in common\n\n\n\ndisjoint\nA and B have no points in common\nintersects\n\n\nequals\nA and B are topologically equal: node order or number of nodes may differ; identical to A contains B and A within B\n\n\n\nequals_exact\nA and B are geometrically equal, and have identical node order\n\n\n\nintersects\nA and B are not disjoint\ndisjoint\n\n\nis_within_distance\nA is closer to B than a given distance\n\n\n\nwithin\nNone of the points of B are outside A\ncontains\n\n\ntouches\nA and B have at least one boundary point in common, but no interior points\n\n\n\noverlaps\nA and B have some points in common; the dimension of these is identical to that of A and B\n\n\n\nrelate\nGiven a mask pattern, return whether A and B adhere to this pattern\n\n\n\n\nSee the Geometries chapter of Spatial Data Science for a full treatment that also covers unary and binary measures as well as unary, binary and n-ary transformers\n\n\n\n\n\n\n\n\nFor those who are interested in a deeper understanding of spatial predicates and operating on geometric relationships in R or elsewhere it’s worth taking some time exploring the Dimensionally Extended Nine-Intersection Model (DE-9IM) - a topological model (and a standard) that describes the relationship between any two geometries in two-dimensional space.\nSpatial features have one of the four dimension values:\n\n0 for points\n1 for lines or linear features\n2 for polygons or polygon features\nF or false for empty geometries\n\nThe DE-9IM matrix provides a way to classify geometry relations using the set {0,1,2,F} or {T,F}.\nThe DE-9IM matrix is based on a 3x3 intersection matrix testing the following relations:\n\nII, IE, IB\nBI, BE, BB\nEI, EE, EB\n\n\n\n\n\n\n\n\n\nWith a {T,F} matrix using the I,B, E space, there are 512 possible relations that can be grouped into binary classification schemes.\nAbout 10 of these spatial predicates have common names such as intersects, touches, within, contains. These are the binary predicates we’ve listed in previous table.\nSee the Binary predicates and DE-9IM section in Spatial Data Science as well as succinct overview in slides for a previous workshop by Mike Johnson",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#measures-and-units",
    "href": "geoprocessing.html#measures-and-units",
    "title": "3  Geoprocessing",
    "section": "\n3.3 Measures and Units",
    "text": "3.3 Measures and Units\nMeasures (with sf) make use of the underlying GEOS library, as well as the R units library that provides measure units for R vectors. Once a coordinate reference system has been defined for features, we often want to ask questions of our data such as:\n\nHow long is a line or a polygon perimeter (unit)\nWhat is the area of a polygon (unit^2)\nHow far apart / close together are objects from each other (unit)\n\nSome examples using county and gage datasets we’ve seen in previous section (with refresher again on pulling in data from a .csv file with x and y information and making it spatial):\n\ngages &lt;- read_csv(system.file(\"extdata\", \"Gages_flowdata.csv\", package = \"awra2020spatial\")) |&gt; \n  dplyr::select(SOURCE_FEA, STATE, LAT_SITE, LON_SITE) |&gt; \n  st_as_sf(coords = c(\"LON_SITE\", \"LAT_SITE\"), crs = 4269)\nst_distance(gages[1,], gages[2,])\n\nUnits: [m]\n         [,1]\n[1,] 58822.95\n\n\n\ncounties &lt;- counties(\"Oregon\", cb = TRUE)\noptions(scipen=3)\nprint(paste0('The total area of all counties in Oregon is: ',sum(st_area(counties))))\n\n\n\n\n\n\n\nExercise\n\n\n\nHow did st_distance know to return the distance between our 2 gages in meters? What if we want that distance in feet? Or kilometers? Or our total area in Oregon in km2? There are a couple approaches:\n\nyou could set a projection that uses the units you want reported\nyou could simply look up the conversion factor and apply it manually\nyou can make use of the units library to explicitly set your units for the data\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSetting the projection for the desired units\n\n\ngages_ft &lt;- st_transform(gages, 2994)\nst_distance(gages_ft[1,], gages_ft[2,])\n\nUnits: [foot]\n         [,1]\n[1,] 193550.5",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#spatial-subsetting",
    "href": "geoprocessing.html#spatial-subsetting",
    "title": "3  Geoprocessing",
    "section": "\n3.4 Spatial Subsetting",
    "text": "3.4 Spatial Subsetting\nSpatial subsetting is analogous to attribute subsetting - with sf objects, we can use square bracket ([]) notation to take a spatial object and return a new object that contains only the features that relate in space to another spatial object (i.e. are within, intersect, are within distance of, are spatially disjoint, etc.).\nWe use the simple syntax of x[y,] to perform a spatial subset with the default operation of ‘intersects’: x[y,] is identical to x[y, , op=st_intersects]. We could also provide a different spatial predicate such as x[y, , op = st_disjoint].\nLet’s run through a couple examples.\nFirst we can demonstrate some very simple spatial subsetting examples using a particular county (polygon) in Oregon and Oregon cities (points).\n\nor_cities &lt;- read_sf(system.file(\"extdata/cities.shp\", package = \"Rspatialworkshop\"))\nmult_cnty&lt;- aoi_get(state = \"OR\", county= \"Multnomah\") |&gt; \n  st_transform(st_crs(or_cities)) # project counties to cities\nmapview(mult_cnty, alpha.regions=.07, color='black', lwd=2) + mapview(or_cities)\n\n\n\n\n\nSpatially subset cities within Multnomah County:\n\nmult_cities &lt;- or_cities[mult_cnty,]\n# or\nmult_cities &lt;- or_cities[mult_cnty, , op=st_intersects]\nmapview(mult_cnty, alpha.regions=.07, color='black', lwd=2) + mapview(mult_cities)\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nGiven our explanation above of using different spatial predicates in subsetting operations (e.g. st_disjoint, st_contains, st_is_within_distance) try:\n\nselecting and mapping cities outside of Multnomah county\nselecting and mapping cities within 50 kilometers of Multnomah county (or whatever distance you like)\nusing an attribute selection to select a city (or several cities) by name somewhere else in the state. Using these cities, how would we select and map just the county the contains this city / cities? Hint: we’ll need to pull in all counties of Oregon by modifying AOI_get()\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOutside Multnomah county:\n\nout_mult_cities &lt;- or_cities[mult_cnty, , op=st_disjoint]\nmapview(mult_cnty, alpha.regions=.07, color='black', lwd=2) + mapview(out_mult_cities)\n\n\n\n\n\nCities within 50km of Multnomah county:\n\nclose_mult_cities &lt;- or_cities[mult_cnty, , op=st_is_within_distance,dist=50000]\nmapview(mult_cnty, alpha.regions=.07, color='black', lwd=2) + mapview(close_mult_cities)\n\n\n\n\n\nCounty that contains selected cities:\n\ncounties &lt;- aoi_get(state='Oregon', county='all') |&gt; \n  st_transform(st_crs(or_cities))\nmy_cities &lt;- or_cities |&gt; \n  dplyr::filter(CITY %in% c('ASHLAND','BURNS','HOOD RIVER'))\nsel_counties &lt;- counties[my_cities, , op=st_contains]\nmapview(sel_counties, alpha.regions=.07, color='black', lwd=2) + mapview(my_cities)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#spatial-join",
    "href": "geoprocessing.html#spatial-join",
    "title": "3  Geoprocessing",
    "section": "\n3.5 Spatial Join",
    "text": "3.5 Spatial Join\nOften we want to join information from one spatial dataset to another based on a spatial relationship rather than attribute relationships - joining attribute data should be a familiar concept to everyone and many of the principles are the same. st_join will add new columns from from a source spatial dataset to the target spatial dataset.\nBy default st_join performs a left join (all rows in the target including rows with no match in the source data) - but you can also do an inner join by setting left=FALSE.\nWe can demonstrate the most basic spatial join using our Oregon counties and cities data - here we simply get the county name for every city based on what county each city lands in.\n\ncty_cnty &lt;- st_join(or_cities, counties['name'])\ndplyr::glimpse(cty_cnty)\n\nRows: 898\nColumns: 8\n$ AREA      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ PERIMETER &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ CITIES_   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ CITIES_ID &lt;dbl&gt; 1658, 1368, 1366, 1382, 1384, 1380, 1376, 1370, 1378, 1386, …\n$ CITY      &lt;chr&gt; \"MULINO\", \"HAMMOND\", \"FORT STEVENS\", \"GLIFTON\", \"BRADWOOD\", …\n$ FLAG      &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, …\n$ geometry  &lt;POINT [foot]&gt; POINT (776899.8 1272019), POINT (439320.8 1638725),…\n$ name      &lt;chr&gt; \"Clackamas\", \"Clatsop\", \"Clatsop\", \"Clatsop\", \"Clatsop\", \"Cl…\n\n\nThis is equivalent to:\n\ncty_cnty &lt;- st_join(or_cities, counties['name'], .predicate=st_intersects)\ndplyr::glimpse(cty_cnty)\n\nRows: 898\nColumns: 8\n$ AREA      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ PERIMETER &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ CITIES_   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ CITIES_ID &lt;dbl&gt; 1658, 1368, 1366, 1382, 1384, 1380, 1376, 1370, 1378, 1386, …\n$ CITY      &lt;chr&gt; \"MULINO\", \"HAMMOND\", \"FORT STEVENS\", \"GLIFTON\", \"BRADWOOD\", …\n$ FLAG      &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, …\n$ geometry  &lt;POINT [foot]&gt; POINT (776899.8 1272019), POINT (439320.8 1638725),…\n$ name      &lt;chr&gt; \"Clackamas\", \"Clatsop\", \"Clatsop\", \"Clatsop\", \"Clatsop\", \"Cl…\n\n\n\n\n\n\n\n\nExercise\n\n\n\nOften we want to find what features are within a certain specified distance of other features, or what features are closest to a set of features. st_join can answer these questions by supplying the st_is_within_distance\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nSetting the projection for the desired units\n\n\ngages_ft &lt;- st_transform(gages, 2994)\nst_distance(gages_ft[1,], gages_ft[2,])\n\nUnits: [foot]\n         [,1]\n[1,] 193550.5",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#buffer-and-dissolve",
    "href": "geoprocessing.html#buffer-and-dissolve",
    "title": "3  Geoprocessing",
    "section": "\n3.6 Buffer and Dissolve",
    "text": "3.6 Buffer and Dissolve\nTypical GIS operations creating buffers around features (points, lines or polygons) and dissolving polygon boundaries based on a common attribute - here we show how to do these common GIS tasks in an R workflow.\nWe’ll demonstrate dissolving using both tidyverse functions in conjunction with simple features as well as using the st_union() function in sf.\nLet’s use our Oregon cities and counties data again for this.\nFirst we’ll demonstrate buffering which is a simpler operation using st_buffer with a supplied distance.\nWe pick our largest cities and buffer them by some arbitrary distance - we’ll say 20 miles (note below we convert feet to miles).\n\n# Filter for metro areas\nmetros &lt;- or_cities |&gt; \n  dplyr::filter(CITY %in% c('PORTLAND','SALEM','EUGENE','CORVALLIS','BEND','MEDFORD'))\n# Buffer larger cities\nmetro_areas &lt;- metros |&gt; \n  st_buffer(105600)\nmapview(metro_areas)\n\n\n\n\n\nNext we show both methods to dissolve, categorizing Oregon counties as urban or rural and dissolving on these categories.\n\n# urban area\ncounties &lt;- st_transform(counties, st_crs(metro_areas)) # crs same\n\nurban_counties &lt;- counties[metro_areas, ,op=st_intersects] # subsetting\n\nurban &lt;- urban_counties |&gt;  # Dissolve\n  st_union() |&gt; # unite geometries\n  st_sf() |&gt; # promote geometry back to data frame\n  dplyr::mutate(urban=TRUE) # assign urban\n\n# rural area\n# here we use tidyverse method to dissolve\nrural &lt;- counties |&gt; \n  dplyr::filter(!name %in% urban_counties$name) |&gt; \n  dplyr::group_by(state_abbr) |&gt; # just group by state - all the same\n  dplyr::mutate(AREA= geometry |&gt; st_area()) |&gt; \n  dplyr::summarise(AREA = sum(AREA)) # this is the cool part!\n\nmapview(urban, col.region='red') + mapview(rural)\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWe made use of the summarise method above with our sf features to perform a dissolve - by - summarise has a special argument - do_union which is set to TRUE by default and unions grouped geometries.\nReview and experiment with different tidyverse methods that honor sf objects using the counties and cities data. These methods include:\n\nfilter\nselect\ngroup_by\nungroup\nmutate\ntransmute\nrowwise\nrename\nslice\nsummarise\ndistinct\n\ngather\n\npivot_longer\nspread\nnest\nunnest\nunite\nseparate\nseparate_rows\nsample_n\nsample_frac\n\nAn exhaustive list - when used with sf objects they simply preserve geometry - remember geometry is sticky and sf is tidyverse-compliant. You can use st_drop_geometry if you want to return tidyverse operations on sf features as tibbles or data.frames (or corece features to data.frames or tibbles).\nThis section in Spatial Data Science provides a nice background, as well as this vignette from the Geocomputation with R book on pitfalls to be aware of with spatial data in conjunction with tidyverse.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#clipping",
    "href": "geoprocessing.html#clipping",
    "title": "3  Geoprocessing",
    "section": "\n3.7 Clipping",
    "text": "3.7 Clipping\nClipping is another extremely common GIS operation, and it’s simply a form of spatial subsetting that makes changes to the geometry list columns of affected features - it only applies to more complex geometries like lines, polygons and multi-lines and multi-polygons.\nLet’s use our city buffer for Corvallis and counties to demonstrate clipping. We’ll ask for just the portions of counties that intersect our ‘metro’ buffer around Corvallis.\nLet’s see what it looks like first:\n\nplot(metro_areas[2,c('geometry')],col = \"lightgrey\", axes=TRUE) \nplot(counties[metro_areas[2,],c('geometry')],border = \"grey\", add = TRUE)\n\n\n\n\n\n\n\nClip and show results:\n\nmetro_county_area &lt;- st_intersection(metro_areas[2,], counties)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\nplot(st_geometry(metro_county_area), border = \"grey\", axes = TRUE) # intersecting area\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou may encounter errors like this when running geoprocessing operations like st_join in R:\nError in wk_handle.wk_wkb(wkb, s2_geography_writer(oriented\n= oriented,  :  Loop 0 is not valid: Edge 772 crosses edge 774\nRunning st_make_valid might not fix.\nYou may need to turn off spherical geometry - sf_use_s2(TRUE), run st_make_valid, and then turn spherical geometry back on - sf_use_s2(FALSE) See background on S2 here and discussion of S2 related issues here",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#centroids-and-type-transformations",
    "href": "geoprocessing.html#centroids-and-type-transformations",
    "title": "3  Geoprocessing",
    "section": "\n3.8 Centroids and Type Transformations",
    "text": "3.8 Centroids and Type Transformations\nWe can extract the centroid of features a couple different ways - typically we are looking for the geographic centroid which is the center of mass of a feature and can fall outside the boundaries of a feature for complex features. If we want our centroids to always be inside our features we need to ask for a point on surface. Lastly, casting in sf allows us to perform type transformations from one geometry type to another.\nWe’ll use our county data and bring in some river flow line data using the dataRetrieval package as well to demonstrate with linear features.\n\nSouthSantiam &lt;- dataRetrieval::findNLDI(nwis = \"14187200\", nav = \"UT\", find = \"flowlines\", distance_km=10)\n  \nSouthSantiam &lt;- SouthSantiam$UT_flowlines\nSouthSantiam &lt;- SouthSantiam |&gt; \n  st_transform(st_crs(counties))\n\nriv_cent1 &lt;- st_centroid(SouthSantiam)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nriv_cent2 &lt;- st_point_on_surface(SouthSantiam)\n\nWarning: st_point_on_surface assumes attributes are constant over geometries\n\nsel_counties &lt;- counties |&gt; \n  dplyr::filter(name %in% c('Marion','Yamhill','Polk','Benton','Multnomah','Clackamas','Linn','Washington'))\n\ncnt_cent1 &lt;- st_centroid(sel_counties)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\ncnt_cent2 &lt;- st_point_on_surface(sel_counties)\n\nWarning: st_point_on_surface assumes attributes are constant over geometries\n\np1 = tm_shape(sel_counties) + tm_borders() +\n  tm_shape(cnt_cent1) + tm_symbols(shape = 1, col = \"black\", size = 0.5) +\n  tm_shape(cnt_cent2) + tm_symbols(shape = 1, col = \"red\", size = 0.5)  \np2 = tm_shape(SouthSantiam) + tm_lines() +\n  tm_shape(riv_cent1) + tm_symbols(shape = 1, col = \"black\", size = 0.5) +\n  tm_shape(riv_cent2) + tm_symbols(shape = 1, col = \"red\", size = 0.5)  \ntmap_arrange(p1, p2, ncol = 2)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#simplification",
    "href": "geoprocessing.html#simplification",
    "title": "3  Geoprocessing",
    "section": "\n3.9 Simplification",
    "text": "3.9 Simplification\nWith simplification we can generalize vector line and polygon objects - this is often useful to improve cartographic display as well as to reduce memory use and disk space used by complex geometric features. st_simplify in sf provides basic simplification implementing the Douglas-Peucker algorithm via GEOS to prune vertices. See rmapshaper and mapshaper for more extensive simplification algorithms.\n\nSant_simp = st_simplify(SouthSantiam, dTolerance = 500)  # 500 m\np1 = tm_shape(SouthSantiam) + tm_lines() \np2 = tm_shape(Sant_simp) + tm_lines() \ntmap_arrange(p1, p2, ncol = 2)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "geoprocessing.html#raster-operations",
    "href": "geoprocessing.html#raster-operations",
    "title": "3  Geoprocessing",
    "section": "\n3.10 Raster operations",
    "text": "3.10 Raster operations\n\n3.10.1 Cropping\nWe’ll use some built in data from a previous workshop to demonstrate a number of simple raster geoprocessing operations.\nWe’ll start with an elevation raster and Crater Lake boundary and project both to an local conformal projection (UTM Z10 North)\n\ndata(CraterLake)\nraster_filepath &lt;- system.file(\"extdata\", \"elevation.tif\", package = \"Rspatialworkshop\")\nelevation &lt;- rast(raster_filepath)\nelevation &lt;- project(elevation, \"EPSG:26910\", method = \"bilinear\")\nCraterLake &lt;- st_transform(CraterLake,crs(elevation))\nplot(elevation)\nplot(CraterLake, add=TRUE, col=NA, border='blue')\n\n\n\n\n\n\n\nHere we’ll use crop to crop the elevation raster to the bounding box of our Crater Lake polygon feature\n\nelev_crop = crop(elevation, vect(CraterLake))\nplot(elev_crop)\nplot(CraterLake, add=TRUE, col=NA, border='blue')\n\n\n\n\n\n\n\nAnd finally we can use mask to mask the raster to just inside the polygon outline of Crater Lake National Park.\nNote - if you have a large raster, it makes a HUGE difference to use crop first, then mask - mask is a much more computationally intensive operation so it will pay off to crop first then mask. An interesting twitter thread regarding this just the other day:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelev_mask = mask(elevation, vect(CraterLake))\nplot(elev_mask)\nplot(CraterLake, add=TRUE, col=NA, border='blue')\n\n\n\n\n\n\n\n\n3.10.2 Map Algebra\nWe can divide map algebra into a couple of categories:\n\nLocal - per-cell operations\n\nraster calculator\nreplacing values\nreclassifying\ncalculating indices\n\n\nFocal (neighborhood operations)\n\nsummarizing output cell value as the result of a window (such as a3 x 3 input cell block)\nZonal operations - summarizing raster values for some zones (either another raster or a vector feature)\nGlobal - summarizing values over entire raster(s)\n\n\n\n\n3.10.2.1 Local Operations\nSay we want to convert our elevation raster from meters to feet:\n\nelev_feet = elevation * 3.28084\nelev_feet\n\nclass       : SpatRaster \ndimensions  : 981, 883, 1  (nrow, ncol, nlyr)\nresolution  : 78.76638, 78.76638  (x, y)\nextent      : 536109.7, 605660.4, 4714704, 4791974  (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83 / UTM zone 10N (EPSG:26910) \nsource(s)   : memory\nname        : srtm_12_04 \nmin value   :   1846.880 \nmax value   :   8910.399 \n\n\n\n\n\n\n\n\nHow would we verify the units of our projection? Take a minute to explore crs for terra\n\n\n\nOur max value is 8890, which makes sense - the high point in Crater Lake National Park is Mount Scott at 8,929’.\nWhat if we want to make elevation bins, or classify some elevations as NA with our elevation raster?\n\nreclass &lt;- matrix(c(0, 500, 1, 500, 1000, 2, 1000, 1500, 3, 1500 , 2000, 4, 2000, 2700, 5), ncol = 3, byrow = TRUE)\nreclass\n\n     [,1] [,2] [,3]\n[1,]    0  500    1\n[2,]  500 1000    2\n[3,] 1000 1500    3\n[4,] 1500 2000    4\n[5,] 2000 2700    5\n\nelev_recl = classify(elevation, rcl = reclass)\nplot(elevation)\n\n\n\n\n\n\nplot(elev_recl)\n\n\n\n\n\n\n\n\nelev_new = elevation\nelev_new[elev_new &gt; 2000] = NA\nplot(elev_new)\n\n\n\n\n\n\n\n\n3.10.2.2 Focal Operations\nA simple focal window operation\n\nelev_focal_mean = focal(elevation, \n                   w = matrix(1, nrow = 25, ncol = 25), \n                   fun = mean)\nplot(elev_focal_mean)\n\n\n\n\n\n\n\n\n3.10.2.3 Global Operations\n\nterra::global(elev_mask, fun=\"mean\", na.rm=TRUE)\n\n               mean\nsrtm_12_04 1849.557\n\nterra::global(elev_mask, fun=\"sum\", na.rm=TRUE)\n\n                 sum\nsrtm_12_04 221839618\n\n\n\n3.10.3 Zonal Operations\nHere we demonstrate using the zonal function in terra to summarize a value raster of elevation, using an srtm.tif from spDataLarge, by the zones of NLCD classes using nlcd.tif raster also in the spDataLarge package. We’ll expand more on zonal statistics including for categorical data in the final section of the workshop.\n\nsrtm_path = system.file(\"raster/srtm.tif\", package = \"spDataLarge\")\nsrtm_path\n\n[1] \"C:/Users/mweber/R/library/spDataLarge/raster/srtm.tif\"\n\nsrtm = rast(srtm_path)\nsrtm\n\nclass       : SpatRaster \ndimensions  : 457, 465, 1  (nrow, ncol, nlyr)\nresolution  : 0.0008333333, 0.0008333333  (x, y)\nextent      : -113.2396, -112.8521, 37.13208, 37.51292  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : srtm.tif \nname        : srtm \nmin value   : 1024 \nmax value   : 2892 \n\nnlcd = rast(system.file(\"raster/nlcd2011.tif\", package = \"spDataLarge\"))\nsrtm_utm = project(srtm, nlcd, method = \"bilinear\")\nsrtm_zonal = zonal(srtm_utm, nlcd, na.rm = TRUE, fun = \"mean\")\nsrtm_zonal\n\n   nlcd2011     srtm\n1        11 2227.060\n2        21 1713.980\n3        22 1642.077\n4        23 1569.632\n5        31 1854.069\n6        41 2361.121\n7        42 1867.068\n8        43 2500.253\n9        52 1650.966\n10       71 1644.359\n11       81 1284.106\n12       82 1417.671\n13       90 1254.168\n14       95 1909.590",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Geoprocessing</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Goals and Outcomes",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#goals-and-outcomes",
    "href": "resources.html#goals-and-outcomes",
    "title": "Resources",
    "section": "",
    "text": "Summarize the functionality of modern R packages for handling spatial data.\nDiscuss the retirement of rgdal, rgeos, and maptools and its effect on the rest of the spatial data ecosystem in R.\nProvide additional resources for handling spatial data in R",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#sf",
    "href": "resources.html#sf",
    "title": "Resources",
    "section": "sf",
    "text": "sf\nThe sf R package [@pebesma2018sf] implements an R-based approach to handling spatial data based on simple features, a set of standards that specify how spatial objects are represented by computers. The simple features standards are widely implemented in spatial databases like GIS and GDAL. They have a geometry that describes their location on Earth using a coordinate reference system. Simple features objects in R are called sf objects and build upon R’s standard data frame by adding geometry. sf objects have two main components:\n\nA data.frame with feature attributes\nA list-column with geometries for each feature\n\nYou can operate on sf objects just as you would a operate on a data.frame, and there are many tidyverse operations (e.g., select(), filter()) that work directly with sf objects. All sf functions that operate on spatial data are prefixed by st_, which refers to spatial type. The prefix makes them easy to find via tab (or command-line) completion. For example, to inspect the sf function’s geometry as well-known text, run st_geometry().\nThe sf R package is the modern approach to manipulating spatial data in R using simple features and is designed to completely supersede sp. For more of sf, visit their website here or this overview here.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#terra",
    "href": "resources.html#terra",
    "title": "Resources",
    "section": "terra",
    "text": "terra\nThe terra R package [@hijmans2023terra] is used to create, read, manipulate, and write raster data. Raster data is a spatial data structure that divides a region into rectangles called “cells” or “pixels” that can store one or more values fore each cell. Raster data structures are often called “grids”, a contrast with the “vector” data used to represent points, lines, and polygons as in the sf package. One advantage of the terra package and raster data structures is that it can handle large data sets on disk that are too large to be loaded into memory.\nRaster objects in terra are typically created or read in using the rast() function. Raster objects in terra support common algebraic operations (e.g., +, *), logical operations (e.g., &gt;=, ==), and functionals (e.g., round, log) on raster cells. There are several options for modifying raster objects: crop, which subsets a larger terra object; trim, which removes outer rows and columns with NA values; extend, which adds outer rows and columns with NA values, merge, which merges two or more raster objects into a single object; aggregate and disagg for changing the resolution (cell size) of a raster object; wrap for transforming to a new coordinate reference system; and more. There are also options for computing distances, summary statistics, prediction, and visualization.\nThe terra R package is the modern approach to manipulating raster data in R and is designed to completely supersede raster``. For more ofterra`, visit their website here.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#other-useful-spatial-data-packages",
    "href": "resources.html#other-useful-spatial-data-packages",
    "title": "Resources",
    "section": "Other Useful Spatial Data Packages",
    "text": "Other Useful Spatial Data Packages\n\nstars for handling spatio-temporal vector and raster data (link here)\nleaflet for an R package that accesses leaflet, a population JavaScript library for interactive maps (link here)\ntmap for generating thematic maps in R for (link here)\nmapview for a different approach to interacting with the leaflet Javascript library (link here)\nggplot2 for general graphics in R (link here), with a focus on geom_sf() (link here)",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#retirement-of-rgdal-rgeos-and-maptools-plan-for-sp",
    "href": "resources.html#retirement-of-rgdal-rgeos-and-maptools-plan-for-sp",
    "title": "Resources",
    "section": "Retirement of rgdal, rgeos, and maptools; Plan for sp",
    "text": "Retirement of rgdal, rgeos, and maptools; Plan for sp\nThe rgdal, rgeos, and maptools R packages won’t be available on CRAN after October, 2023. Preparation for these retirements has been worked on for quite some time and is one of the motivating factors in pursuing modern alternatives like sf and terra. The sp package will still be available from CRAN, but it won’t be actively maintained, and sf should be used instead. To learn more about these retirements and understand how you may be affected, visit this link here.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#r-spatial-resources",
    "href": "resources.html#r-spatial-resources",
    "title": "Resources",
    "section": "R Spatial Resources",
    "text": "R Spatial Resources\n\nSpatial Data Science With Applications in R\nR Spatial - Spatial Data Science with R\nGeocomputation with R\nR-Spatial Task View\nR-Spatial Website\nModern Geospatial Data Analysis with R by Zev Ross **Spatial Statistics for Data Science: Theory and Practice with R\nSIGR2021 Summer School\nSpatial Data Science - Pebesma and Bivand\nSpatial Data Science Course- Prof. Adam Wilson\nIntroduction to Mapping and Spatial Analysis with R\nR Spatial Workshop for EPA R User Group\nIntro to GIS and Spatial Analysis by Manuel Gimond\nFOSS4G2019 R for Geospatial Processing\nAn Introduction to Spatial Analysis and Mapping in R\nEarth Analytics Spatial Data in R\nHydroinformatics at VT: Extensive Notes and exercises for a course on data analysis techniques in hydrology using the programming language R",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#r-vector-processing-simple-features-resources",
    "href": "resources.html#r-vector-processing-simple-features-resources",
    "title": "Resources",
    "section": "R Vector Processing / Simple Features Resources",
    "text": "R Vector Processing / Simple Features Resources\n\nSimple Features for R\nSpatial Data in R: New Directions\nsp-sf Migration\nAn Exploration of Simple Features for R\nSimple Features: Building Spatial Data Pipelines in R\nTidy spatial data in R: using dplyr, tidyr, and ggplot2 with sf",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#r-raster-resources",
    "href": "resources.html#r-raster-resources",
    "title": "Resources",
    "section": "R Raster Resources",
    "text": "R Raster Resources\n\nterra\nSpatial Data Science with R and terra\nstars - spatiotemporal arrays\nWageningen University Intro to Raster\nWageningen University Advanced Raster Analysis\nThe Visual Raster Cheat Sheet GitHub Repo\nRastervis",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#r-mapping-resources",
    "href": "resources.html#r-mapping-resources",
    "title": "Resources",
    "section": "R Mapping Resources",
    "text": "R Mapping Resources\n\nmapview\nLeaflet for R\ntmap\nZev Ross Creating beautiful demographic maps in R with the tidycensus and tmap packages\nGeocomputation with R: Making maps with R\nNico Hahn: Making Maps with R R",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#web-services-in-r",
    "href": "resources.html#web-services-in-r",
    "title": "Resources",
    "section": "Web Services in R",
    "text": "Web Services in R\n\nAccessing REST API (JSON data) using httr and jsonlite\nWorking with Geospatial Hydrologic Data Using Web Services (R)",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#general-r-resources",
    "href": "resources.html#general-r-resources",
    "title": "Resources",
    "section": "General R Resources",
    "text": "General R Resources\n\nGoogle R Style Guide\nAdvanced R by Hadley Wickham\nR for Data Science",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#previous-r-spatial-workshops",
    "href": "resources.html#previous-r-spatial-workshops",
    "title": "Resources",
    "section": "Previous R Spatial Workshops",
    "text": "Previous R Spatial Workshops\n\n‘Working with Geospatial Hydrologic Data for Watershed Analyses in R and Python Using Web Services’ Workshop for the International Conference on the Watersheds\nAWRA 2022 Geospatial R and Python Workshop\nEPA R User Group Spatial Workshop 2021\nAWRA 2020 Spatial Analysis in R Workshop\nAWRA 2018 Geospatial R Workshop",
    "crumbs": [
      "Resources"
    ]
  }
]